{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Horese07/Elhoucine_Elachguar_ADIA-G2-Java/blob/main/ProjetCNN_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIyYyJCPKIlX"
      },
      "source": [
        "                          \n",
        "<center><h1><a><strong> Projet de Classification de Chiffres Manuscrits avec CNN<strong></a> </h1></center>\n",
        "<fieldset>\n",
        "<center><h2> : Classification de Chiffres Manuscrits avec Réseaux de Neurones Convolutifs\n",
        "(CNN) sur le jeu de données MNIST</h2></center>\n",
        "</fielset>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8z0I8dYAGI"
      },
      "source": [
        "#<center><h1><strong><a>I.Introduction : </a></strong>Contexte et Objectifs</h1></center>\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9pCI_V8aBOT"
      },
      "source": [
        "<h3><i>Contexte:</i><h3>\n",
        "\n",
        " <p>La reconnaissance de chiffres manuscrits est un problème classique de la vision par ordinateur et de l'apprentissage automatique. Ce problème consiste à identifier des chiffres écrits à la main, ce qui présente plusieurs défis en raison des variations dans le style d'écriture de différentes personnes. Le jeu de données MNIST (Modified National Institute of Standards and Technology) est largement utilisé pour ce type de tâches. Il contient 70,000 images en niveaux de gris de 28x28 pixels représentant les chiffres de 0 à 9, avec 60,000 images destinées à l'entraînement et 10,000 images pour le test.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6VjaQabOX74"
      },
      "source": [
        "\n",
        " <h3><i>Objectif:</i><h3>\n",
        "<p>L'objectif de ce projet est de construire un modèle de réseau de neurones convolutifs (CNN) capable de classifier les chiffres manuscrits du jeu de données MNIST avec une haute précision. Pour atteindre cet objectif, les étapes suivantes seront suivies :\n",
        "\n",
        "1.   <strong>Prétraitement des Données :</strong> Préparer les données en les normalisant et en appliquant le one-hot encoding aux labels.\n",
        "2.   <strong>Construction du Modèle CNN :</strong> Construire une architecture CNN adaptée à la classification d'images de chiffres manuscrits.\n",
        "3.   <strong>Entraînement et Évaluation du Modèle :</strong> Entraîner le modèle sur les données d'entraînement et l'évaluer sur les données de validation et de test.\n",
        "4.   <strong>Visualisation des Résultats :</strong> Analyser les performances du modèle à travers des graphiques et des courbes d'apprentissage.\n",
        "5.<strong>Améliorations et Expérimentations :</strong> Expérimenter avec des techniques d'amélioration comme l'augmentation de données pour améliorer la robustesse et la précision du modèle.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "665RuLlUacwN"
      },
      "source": [
        "#<center> <h2><strong><a>II.Prétraitement des Données<a></strong></h2></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNU-s3wpbzd-"
      },
      "source": [
        "<h3><i>1. Importation des Bibliothèques<i></h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THILbS-V89z9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "from skimage.transform import  rotate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "QQCv32gOQwg9",
        "outputId": "7784659b-b8ca-4859-f577-ac67e9f89d83"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmBDWH930Ggf"
      },
      "outputs": [],
      "source": [
        "# Create fucnction for add and convert images to gray\n",
        "def check_and_convert_to_grayscale(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Check if image loading was successful\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n",
        "\n",
        "    # Check the number of channels in the image\n",
        "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "        # Convert to grayscale\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_image = image\n",
        "\n",
        "    return gray_image\n",
        "\n",
        "def preprocess_image(image_path, img_size=(28, 28)):\n",
        "    # Convert to grayscale and resize\n",
        "    image = check_and_convert_to_grayscale(image_path)\n",
        "    image_resized = cv2.resize(image, img_size)\n",
        "\n",
        "    # Normalize the image\n",
        "    image_normalized = image_resized / 255.0\n",
        "\n",
        "    return image_normalized\n",
        "\n",
        "def load_my_images(directory, img_size=(28, 28)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            label = int(filename.split('_')[0])  # like '3_image1.jpg' donc label = 3\n",
        "            image_path = os.path.join(directory, filename)\n",
        "            image = preprocess_image(image_path, img_size)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfnvub-Pcu6q"
      },
      "source": [
        "<h3><i>2. Chargement et Prévisualisation des Données</i></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iimDzlaA4erC"
      },
      "source": [
        "First We will add our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIr3PYpX4d5J"
      },
      "outputs": [],
      "source": [
        "my_images, my_labels = load_my_images('/content/drive/MyDrive/Colab Notebooks/Numbers')\n",
        "\n",
        "\n",
        "\n",
        "# Visualiser quelques exemples d'images\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(20):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(my_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(my_labels[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvDTPTOD6I7u"
      },
      "source": [
        "Right now we Are going to augment the our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-vQ31Ka6Wlv"
      },
      "outputs": [],
      "source": [
        "# Create a new array to store the augmented images\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "\n",
        "for image, label in zip(my_images, my_labels):\n",
        "    # Generate a random angle for rotation\n",
        "    random_angle = np.random.randint(low=0, high=60)\n",
        "    # Rotate the image\n",
        "    rotated_image = rotate(image, angle=random_angle)\n",
        "    # Convert the rotated image to a NumPy array\n",
        "    rotated_image = np.array(rotated_image)\n",
        "    rotated_lablel = np.array(label)\n",
        "    # Append the rotated image to augmented_images\n",
        "    augmented_images.append(rotated_image)\n",
        "    augmented_labels.append(rotated_lablel)\n",
        "\n",
        "# Convert augmented_images to numpy array\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "# Add augmented images to the original my_images array\n",
        "my_images = np.concatenate((my_images, augmented_images))\n",
        "my_labels = np.concatenate((my_labels, augmented_labels))\n",
        "\n",
        "# Visualize the rotated images\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(4):\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow(augmented_images[i])  # Visualizing augmented images\n",
        "    title = \"Rotated image {}\".format(i+1, augmented_labels[i])\n",
        "    ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdgjazI0beq1"
      },
      "source": [
        "after that we add our data to the data from mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJfk9kBa9DP2"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "# Ajouter les images augmentées à train_images\n",
        "train_images = np.concatenate((train_images, my_images))\n",
        "train_labels = np.concatenate((train_labels, my_labels))\n",
        "\n",
        "# Visualiser quelques exemples d'images\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[i])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtaUAbF7jG3R"
      },
      "source": [
        "Le jeu de données MNIST contient des images manuscrites de chiffres allant de 0 à 9. Il y a donc 10 classes dans ce dataset, chaque classe correspondant à un chiffre distinct :\n",
        "\n",
        "\n",
        "0.  – Chiffre 0\n",
        "1.  – Chiffre 1\n",
        "2.  – Chiffre 2\n",
        "3.  – Chiffre 2\n",
        "4.  – Chiffre 4\n",
        "5.  – Chiffre 5\n",
        "6.   – Chiffre 6\n",
        "7.   – Chiffre 7\n",
        "8.   – Chiffre 8\n",
        "9.   – Chiffre 9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruFPKOh8dJBi"
      },
      "source": [
        "<h3><i>3. Prétraitement des Données</i><h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRkoASiRBai3"
      },
      "outputs": [],
      "source": [
        "#Normalisation des Images\n",
        "# Les valeurs de pixels vont de 0 à 255. En divisant par 255, on normalise ces\n",
        "# valeurs pour qu'elles soient dans la plage [0, 1].\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmFR4OWwB2tH"
      },
      "outputs": [],
      "source": [
        "#One-Hot Encoding des Labels\n",
        "# Convertir les labels des chiffres en un format binaire (one-hot encoding) pour\n",
        "# qu'ils soient compatibles avec la couche de sortie du modèle CNN.\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqv5c0ZLEmEY"
      },
      "outputs": [],
      "source": [
        "#Reshape des Images\n",
        "# Adapter la forme des images pour qu'elles soient compatibles avec\n",
        "# l'architecture CNN, qui attend des images avec une dimension de canal\n",
        "# supplémentaire.\n",
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcPqr5HcGExC"
      },
      "outputs": [],
      "source": [
        "# Division des données en ensemble d'entraînement et de validation\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLqYHfiNgdTO"
      },
      "source": [
        "#<center> <h2><strong><a>III.Construction du Modèle CNN</a></strong></h2></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0hMk4zxgjYe"
      },
      "source": [
        "\n",
        "*  <strong>Convolution 2D :</strong> Applique un filtre de convolution sur l'image pour extraire des caractéristiques (features).\n",
        "*  <strong> ReLU : </strong>Fonction d'activation rectifiée qui introduit la non-linéarité.\n",
        "* <strong> MaxPooling : </strong>Réduit les dimensions spatiales de l'image, conservant les informations les plus importantes.\n",
        "*   <strong>Flatten :</strong> Aplatie les matrices en un vecteur.\n",
        "*<strong>  Dense : </strong>Couche entièrement connectée qui apprend les combinaisons non linéaires de caractéristiques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqHJPtLElKsM"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7IOKiFwz63W"
      },
      "source": [
        "#<center> <h2><strong><a>IV.Entraînement et Évaluation du Modèle </a></strong></h2></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It5FH3iI0gHI"
      },
      "source": [
        "\n",
        "*  <strong> Adam Optimizer :</strong> Algorithme d'optimisation adaptatif qui ajuste les taux d'apprentissage pour chaque paramètre.\n",
        "*  <strong> Categorical Crossentropy :</strong> Fonction de perte utilisée pour les classifications multi-classes.\n",
        "\n",
        "* <strong> Metrics : </strong>accuracy mesure la proportion de prédictions correctes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXHIzTs00SPn"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5,\n",
        "                    validation_data=(val_images, val_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PkT351VoGuV"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(test_images[7].reshape(1, 28, 28, 1))\n",
        "label = np.argmax(pred)\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xftgYkQC2HjN"
      },
      "source": [
        "# <center><h2><strong><a>V.Évaluation et Analyse du Modèle</a></strong></h2></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwnGWo833GRc"
      },
      "source": [
        "<p>Les courbes d'apprentissage montrent l'évolution de l'exactitude pendant l'entraînement et la validation, aidant à identifier des problèmes de surapprentissage ou de sous-apprentissage.<p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHFU8VIE22rN"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n",
        "\n",
        "# Visualisation des courbes d'apprentissage\n",
        "losses = pd.DataFrame(history.history)\n",
        "losses[['accuracy', 'val_accuracy']].plot()\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-azjdbtLkwi"
      },
      "source": [
        "La courbe d'accuracy en fonction des epochs montre que le modèle CNN est bien entraîné sur le jeu de données MNIST. L'accuracy atteint un plateau après quelques epochs, indiquant que le modèle a appris les caractéristiques essentielles des données sans surapprendre. La courbe stable et élevée de l'accuracy de validation confirme la capacité du modèle à généraliser correctement aux nouvelles données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otm3SPZWLqmD"
      },
      "outputs": [],
      "source": [
        "losses[['loss', 'val_loss']].plot()\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ue-vjQbMWx6"
      },
      "source": [
        "La courbe de perte montre que votre modèle CNN est bien entraîné sur le jeu de données MNIST. La perte d'entraînement diminue régulièrement, indiquant une bonne progression de l'apprentissage. La perte de validation reste basse avec des fluctuations modérées, suggérant que le modèle généralise bien aux nouvelles données, avec une légère tendance au surajustement dans les dernières epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xK6qQmD34Bm"
      },
      "source": [
        "#<center> <h2><strong><a>VI.Améliorations et Expérimentations</a></strong></h2><center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ah_IF65Hpa"
      },
      "source": [
        "<i>L'augmentation de données génère des variantes des images d'entraînement en appliquant des transformations aléatoires comme des rotations, des zooms et des translations. Cela aide à améliorer la généralisation du modèle en le rendant plus robuste aux variations des données.<i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTLAesAc48MA"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "datagen.fit(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mop1-CB-mgpQ"
      },
      "outputs": [],
      "source": [
        "history = model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
        "                    epochs=10,\n",
        "                    validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "firhogBjeXnE"
      },
      "outputs": [],
      "source": [
        "# Générer un batch d'images augmentées\n",
        "augmented_images, augmented_labels = next(datagen.flow(train_images, train_labels, batch_size=25))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(augmented_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(np.argmax(augmented_labels[i]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnTeyojlNtcA"
      },
      "source": [
        "#<center> <h2><strong><a>VII.Évaluation sur les Données de Test</a></strong></h2><center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ct3qFWYvTSW"
      },
      "source": [
        "<p>Formule : Precision = TP / (TP + FP)</p>\n",
        "<p>Formule : recall   = TP / (TP + FN)</p>\n",
        "<p>Formule : f1-Score = 2*(Recall * Precision)/(Recall + Precsion)</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah0rKvJ8N2Sy"
      },
      "outputs": [],
      "source": [
        "# Évaluer la performance sur les données de test\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n",
        "\n",
        "# Prédictions sur les données de test\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Convertir les prédictions et les labels de test en labels de classe\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Afficher un rapport de classification\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "# Afficher une matrice de confusion\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "print(conf_matrix)\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix , annot = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGIzjMoEmaIx"
      },
      "outputs": [],
      "source": [
        "# Visualisation des prédictions pour quelques exemples\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[i].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(f\"True: {true_labels[i]}, Pred: {predicted_labels[i]}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FzbC6A0p4OL"
      },
      "source": [
        "<h3><i>Creation d'un interface web en utilisant  FLASK</i></h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzeUuucom-Kh"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDqMk-lRnBKr"
      },
      "outputs": [],
      "source": [
        "!pip install flask pyngrok tensorflow pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHyoiNsQnE-Z"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, render_template, request, jsonify\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = load_model('model.h5')\n",
        "\n",
        "def preprocess_image(image, target_size):\n",
        "    if image.mode != \"L\":\n",
        "        image = image.convert(\"L\")\n",
        "    image = image.resize(target_size)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    image = image.astype(\"float32\") / 255.0\n",
        "    return image\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return '''\n",
        " <!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Draw a Digit</title>\n",
        "    <style>\n",
        "        @import url(\"https://fonts.googleapis.com/css2?family=Fredoka:wght@400;600&display=swap\");\n",
        "\n",
        "        body {\n",
        "            background-image: url('https://media.istockphoto.com/id/1470617656/vector/ai-artificial-intelligence-chipset-on-circuit-board-in-futuristic-concept-suitable-for.jpg?s=612x612&w=0&k=20&c=_wC-pphyNI2muaUHG4N9JuYXxJEMDuzx56Dvzr8ZDUk=');\n",
        "            background-size: cover;\n",
        "            background-repeat: no-repeat;\n",
        "            background-position: center;\n",
        "            font-family: 'Fredoka', sans-serif;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "            align-items: center;\n",
        "            height: 100vh;\n",
        "            margin: 0;\n",
        "        }\n",
        "\n",
        "        .card {\n",
        "            background-color: #ffffff;\n",
        "            border-radius: 30px;\n",
        "            text-align: center;\n",
        "            padding: 15px;\n",
        "            max-width: 475px;\n",
        "            margin: 20px;\n",
        "            box-shadow: 20px 20px 20px rgba(0, 0, 0, 0.1), -20px -20px 20px rgba(255, 255, 255, 0.7);\n",
        "        }\n",
        "\n",
        "        .illustration {\n",
        "            margin: 30px;\n",
        "        }\n",
        "\n",
        "        .illustration lottie-player {\n",
        "            width: 200px;\n",
        "            height: 200px;\n",
        "            border-radius: 100%;\n",
        "            overflow: hidden;\n",
        "            margin: 0 auto;\n",
        "            box-shadow: 20px 20px 20px rgba(0, 0, 0, 0.1), -20px -20px 20px rgba(255, 255, 255, 0.7);\n",
        "        }\n",
        "\n",
        "        h1 {\n",
        "            font-size: 2rem;\n",
        "            line-height: 2.2rem;\n",
        "            color: #2e2e2e;\n",
        "            font-weight: bold;\n",
        "            margin: 30px 0;\n",
        "        }\n",
        "\n",
        "        p {\n",
        "            font-size: 1rem;\n",
        "            line-height: 1.3rem;\n",
        "            color: #7e7e7e;\n",
        "            margin: 30px auto;\n",
        "            max-width: 80%;\n",
        "        }\n",
        "\n",
        "        button {\n",
        "            font-size: 1.1rem;\n",
        "            font-weight: bold;\n",
        "            padding: 15px 60px;\n",
        "            border-radius: 25px;\n",
        "            color: white;\n",
        "            border: 0;\n",
        "            margin: 30px 0;\n",
        "            outline: none;\n",
        "            background-color: #81c784;\n",
        "            box-shadow: 10px 10px 10px rgba(0, 0, 0, 0.1), -10px -10px 10px rgba(255, 255, 255, 0.7);\n",
        "            transition: ease all 0.3s;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "\n",
        "        button:hover {\n",
        "            box-shadow: 20px 20px 20px rgba(0, 0, 0, 0.1), -20px -20px 20px rgba(255, 255, 255, 0.7);\n",
        "            transform: translateY(-3px);\n",
        "        }\n",
        "\n",
        "        button:active {\n",
        "            transform: scale(0.9);\n",
        "            box-shadow: inset -1px -1px 3px rgba(0, 0, 0, 0.2), -20px -20px 20px rgba(255, 255, 255, 0.7);\n",
        "        }\n",
        "\n",
        "        canvas {\n",
        "            border: 2px solid #000000;\n",
        "            margin: 20px 0;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"card\">\n",
        "        <div class=\"illustration\">\n",
        "            <lottie-player src=\"https://assets10.lottiefiles.com/packages/lf20_LrcfNr.json\" background=\"white\" speed=\"1\" loop autoplay></lottie-player>\n",
        "        </div>\n",
        "        <h1>Dessiner un nombre entre 0 et 9</h1>\n",
        "        <canvas id=\"canvas\" width=\"280\" height=\"280\"></canvas>\n",
        "        <br>\n",
        "        <button onclick=\"clearCanvas()\">Clear</button>\n",
        "        <button onclick=\"predict()\">Predict from Drawing</button>\n",
        "        <p id=\"resultDrawing\"></p>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"card\">\n",
        "        <h1>Prediction à partir d'une image</h1>\n",
        "        <input type=\"file\" id=\"fileInput\" accept=\"image/*\">\n",
        "        <br>\n",
        "        <button onclick=\"predictImage()\">Predict from Image</button>\n",
        "        <p id=\"resultImage\"></p>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        var canvas = document.getElementById('canvas');\n",
        "        var ctx = canvas.getContext('2d');\n",
        "        ctx.fillStyle = \"black\";\n",
        "        ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "        var drawing = false;\n",
        "\n",
        "        canvas.addEventListener('mousedown', function(e) {\n",
        "            drawing = true;\n",
        "            draw(e);\n",
        "        });\n",
        "\n",
        "        canvas.addEventListener('mouseup', function() {\n",
        "            drawing = false;\n",
        "            ctx.beginPath();\n",
        "        });\n",
        "\n",
        "        canvas.addEventListener('mousemove', draw);\n",
        "\n",
        "        canvas.addEventListener('touchstart', function(e) {\n",
        "            drawing = true;\n",
        "            draw(e.touches[0]);\n",
        "        });\n",
        "\n",
        "        canvas.addEventListener('touchend', function() {\n",
        "            drawing = false;\n",
        "            ctx.beginPath();\n",
        "        });\n",
        "\n",
        "        canvas.addEventListener('touchmove', function(e) {\n",
        "            draw(e.touches[0]);\n",
        "        });\n",
        "\n",
        "        function draw(e) {\n",
        "            if (!drawing) return;\n",
        "            ctx.lineWidth = 10;\n",
        "            ctx.lineCap = 'round';\n",
        "            ctx.strokeStyle = 'white';\n",
        "\n",
        "            ctx.lineTo(e.clientX - canvas.offsetLeft, e.clientY - canvas.offsetTop);\n",
        "            ctx.stroke();\n",
        "            ctx.beginPath();\n",
        "            ctx.moveTo(e.clientX - canvas.offsetLeft, e.clientY - canvas.offsetTop);\n",
        "        }\n",
        "\n",
        "        function clearCanvas() {\n",
        "            ctx.fillStyle = \"black\";\n",
        "            ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "            ctx.beginPath();\n",
        "        }\n",
        "\n",
        "        function predict() {\n",
        "            var dataURL = canvas.toDataURL('image/png');\n",
        "            fetch('/predict', {\n",
        "                method: 'POST',\n",
        "                headers: {\n",
        "                    'Content-Type': 'application/json',\n",
        "                },\n",
        "                body: JSON.stringify({ image: dataURL })\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                document.getElementById('resultDrawing').textContent = 'Prediction: ' + data.prediction;\n",
        "            })\n",
        "            .catch(error => {\n",
        "                console.error('Error:', error);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        function predictImage() {\n",
        "            var fileInput = document.getElementById('fileInput');\n",
        "            var file = fileInput.files[0];\n",
        "            var reader = new FileReader();\n",
        "\n",
        "            reader.onload = function(event) {\n",
        "                var dataURL = event.target.result;\n",
        "                fetch('/predict', {\n",
        "                    method: 'POST',\n",
        "                    headers: {\n",
        "                        'Content-Type': 'application/json',\n",
        "                    },\n",
        "                    body: JSON.stringify({ image: dataURL })\n",
        "                })\n",
        "                .then(response => response.json())\n",
        "                .then(data => {\n",
        "                    document.getElementById('resultImage').textContent = 'Prediction: ' + data.prediction;\n",
        "                })\n",
        "                .catch(error => {\n",
        "                    console.error('Error:', error);\n",
        "                });\n",
        "            };\n",
        "\n",
        "            reader.readAsDataURL(file);\n",
        "        }\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json\n",
        "    image_data = data[\"image\"]\n",
        "    image_data = image_data.split(\",\")[1]\n",
        "    image = base64.b64decode(image_data)\n",
        "    image = Image.open(io.BytesIO(image))\n",
        "    processed_image = preprocess_image(image, target_size=(28, 28))\n",
        "\n",
        "    prediction = model.predict(processed_image).argmax(axis=1)[0]\n",
        "    response = {\"prediction\": int(prediction)}\n",
        "\n",
        "    return jsonify(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olhMUsKGnMC1"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken  2gkZNiq716dFIEXPmP2mAGShvYG_5SDQGJiHkv3cQxzGnEFNL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdcGktfgnO_D"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Démarrer le tunnel ngrok\n",
        "tunnel = ngrok.connect(5000)\n",
        "public_url = tunnel.public_url\n",
        "print(\" * ngrok tunnel: \" + public_url)\n",
        "\n",
        "# Démarrer l'application Flask\n",
        "app.run()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ut8z0I8dYAGI",
        "665RuLlUacwN",
        "sLqYHfiNgdTO",
        "G7IOKiFwz63W",
        "xftgYkQC2HjN",
        "6xK6qQmD34Bm"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}